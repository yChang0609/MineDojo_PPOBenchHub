Environment:
  task: "CombatSpider"
  task_parameter:
    image_size: [224,224]
    step_penalty: 0
    attack_reward: 1
    success_reward: 10
    # max_spawn_range: 10
    # target_quantities: 1
    # max_episode_len: 500

  action_space: "ReducedActionSpace"
  observation: "ImageObservation"

PPO_Training:
  save_name: "PPO_CombatSpider"
  training_step: 10000 #10K
  eval_episode: 10